{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a429bf6f-0771-44ae-8d9e-aba1170ce947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.third_party_integrations import ir_datasets, ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ensure_pyterrier_is_loaded()\n",
    "\n",
    "training_dataset_path = 'ir-lab-jena-leipzig-wise-2023/training-20231104-training'\n",
    "validation_dataset_path = 'ir-lab-jena-leipzig-wise-2023/validation-20231104-training'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6982fffb",
   "metadata": {},
   "source": [
    "### import previously made results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f7ba7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661e80c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = os.environ.get('LM_mu', \"error\" )\n",
    "if mu == \"error\":\n",
    "    raise ValueError(\"Environment variable LM_mu is not set\")\n",
    "mu = float(mu)\n",
    "b= os.environ.get('BM25_b', \"error\" )\n",
    "if b == \"error\":\n",
    "    raise ValueError(\"Environment variable BM25_b is not set\")\n",
    "b = float(b)\n",
    "k_1 = os.environ.get('BM25_k_1', \"error\" )\n",
    "if k_1 == \"error\":\n",
    "    raise ValueError(\"Environment variable BM25_k_1 is not set\")\n",
    "k_1 = float(k_1)\n",
    "\n",
    "evalmetrics = os.environ.get('EVAL_METRIC', \"error\" )\n",
    "if evalmetrics == \"error\":\n",
    "    raise ValueError(\"Environment variable EVAL_METRIC is not set\")\n",
    "evalmetrics = evalmetrics.split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c607be24-80e1-43af-9c73-44599481d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find bm data \n",
    "bm25_path = None\n",
    "for folder in glob(\"input/bm25\"):\n",
    "    if bm25_path:\n",
    "        break\n",
    "    for file in glob(folder + \"/metadata.json\"):\n",
    "        with open(file) as f:\n",
    "            bm25meta = json.load(f)\n",
    "            if bm25meta[\"b\"] == b and bm25meta[\"k_1\"] == k_1:\n",
    "                bm25path = folder\n",
    "                break\n",
    "\n",
    "assert bm25_path, \"BM25 run not found\"\n",
    "#find lm data\n",
    "lm_path = None\n",
    "for folder in glob(\"input/lm\"):\n",
    "    if lm_path:\n",
    "        break\n",
    "    for file in glob(folder + \"/metadata.json\"):\n",
    "        with open(file) as f:\n",
    "            lmmeta = json.load(f)\n",
    "            if lmmeta[\"mu\"] == mu:\n",
    "                lm_path = folder\n",
    "                break\n",
    "\n",
    "bm25_path = bm25_path+\"/out.txt\"\n",
    "lm_path = lm_path+\"/out.txt\"\n",
    "\n",
    "print(\"BM25 path: \", bm25_path)\n",
    "print(\"LM path: \", lm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "642d7638-ef7e-421a-981c-7c955cb41da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_results = pt.io.read_results(bm25_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72072ca1-7cd0-45b8-94b0-9aafe22046e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_results = pt.io.read_results(lm_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f21791-40b2-4558-abac-230013cc5e80",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8720be5c-51ed-4a50-a604-855f39b24548",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = ir_datasets.load(training_dataset_path)\n",
    "training_queries = pt.io.read_topics(ir_datasets.topics_file(training_dataset_path), format='trecxml')\n",
    "training_qrels = pd.DataFrame(training_dataset.qrels_iter()).rename(columns={\"query_id\": \"qid\"})\n",
    "\n",
    "validation_dataset = ir_datasets.load(validation_dataset_path)\n",
    "validation_queries = pt.io.read_topics(ir_datasets.topics_file(validation_dataset_path), format='trecxml')\n",
    "validation_qrels = pd.DataFrame(validation_dataset.qrels_iter()).rename(columns={\"query_id\": \"qid\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec720daa-57af-4070-b3a1-cfcd87c83485",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_results = pd.merge(bm25_results, lm_results, on=['qid', 'docno'])\n",
    "merged_results['features'] = merged_results.apply(lambda row: np.array([row['rank_x'], row['score_y'], row['rank_y']]), axis=1)\n",
    "merged_results = merged_results.rename(columns={'doc_id': 'docno', 'score_x': 'score'})\n",
    "new_df = merged_results[['qid', 'docno', 'score', 'features']]\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb92562-4713-4c96-bbce-61ba2f70a131",
   "metadata": {},
   "source": [
    "## LTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6aa1349-4380-4d05-9a07-a793b9736d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(Transformer(), FUnion(Transformer(), pt.apply.doc_score()))\n"
     ]
    }
   ],
   "source": [
    "bm25 = pt.Transformer.from_df(bm25_results)\n",
    "lm = pt.Transformer.from_df(lm_results)\n",
    "featureA = pt.apply.doc_score(lambda row: row['rank'])\n",
    "\n",
    "pipeline = bm25 >> (lm ** featureA)\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53828ceb-c8fd-4afc-bb49-e8fd0616276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pipeline = pt.Transformer.from_df(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8703a204-471d-4a70-8c9b-bbc65331d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0023848-50e3-4731-a5b9-9515adce3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_qrels = training_qrels.rename(columns={'doc_id': 'docno', 'relevance': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc3b79d7-cd0d-4d26-9aef-af793414ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe = new_pipeline >> pt.ltr.apply_learned_model(rf)\n",
    "rf_pipe.fit(pd.DataFrame(training_queries), training_qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97549b99-737f-4fa7-b507-9fe6d3a80e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier.measures import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cb96c4-7ca2-4721-8e54-808e692d9512",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pt.Experiment([bm25, lm, rf_pipe], pd.DataFrame(training_queries), training_qrels, eval_metrics=evalmetrics, names=[\"BM25 Baseline\", \"LM Baseline\", \"LTR\"])\n",
    "\n",
    "print(result)\n",
    "\n",
    "result.to_csv(\"output/results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
