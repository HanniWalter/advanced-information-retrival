{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a429bf6f-0771-44ae-8d9e-aba1170ce947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.third_party_integrations import ir_datasets, ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ensure_pyterrier_is_loaded()\n",
    "\n",
    "training_dataset_path = 'ir-lab-jena-leipzig-wise-2023/training-20231104-training'\n",
    "validation_dataset_path = 'ir-lab-jena-leipzig-wise-2023/validation-20231104-training'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6982fffb",
   "metadata": {},
   "source": [
    "### import previously made results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f7ba7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c607be24-80e1-43af-9c73-44599481d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_path = \"./bm25.txt\"\n",
    "lm_path = \"./lm.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "642d7638-ef7e-421a-981c-7c955cb41da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_results = pt.io.read_results(bm25_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72072ca1-7cd0-45b8-94b0-9aafe22046e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_results = pt.io.read_results(lm_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f21791-40b2-4558-abac-230013cc5e80",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8720be5c-51ed-4a50-a604-855f39b24548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ir_dataset \"ir-lab-jena-leipzig-wise-2023/training-20231104-training\" from tira.\n",
      "No settings given in /root/.tira/.tira-settings.json. I will use defaults.\n",
      "No settings given in /root/.tira/.tira-settings.json. I will use defaults.\n",
      "Load ir_dataset \"ir-lab-jena-leipzig-wise-2023/validation-20231104-training\" from tira.\n",
      "No settings given in /root/.tira/.tira-settings.json. I will use defaults.\n",
      "No settings given in /root/.tira/.tira-settings.json. I will use defaults.\n",
      "            qid                       query\n",
      "0     q06223196                 car shelter\n",
      "1       q062228                     airport\n",
      "2       q062287        antivirus comparison\n",
      "3     q06223261              free antivirus\n",
      "4       q062291            orange antivirus\n",
      "..          ...                         ...\n",
      "667  q062224914             tax garden shed\n",
      "668  q062224961              land of france\n",
      "669  q062225030   find my training pole job\n",
      "670  q062225194                     gpl car\n",
      "671  q062225197                cheapest car\n",
      "\n",
      "[672 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "training_dataset = ir_datasets.load(training_dataset_path)\n",
    "training_queries = pt.io.read_topics(ir_datasets.topics_file(training_dataset_path), format='trecxml')\n",
    "training_qrels = pd.DataFrame(training_dataset.qrels_iter()).rename(columns={\"query_id\": \"qid\"})\n",
    "\n",
    "validation_dataset = ir_datasets.load(validation_dataset_path)\n",
    "validation_queries = pt.io.read_topics(ir_datasets.topics_file(validation_dataset_path), format='trecxml')\n",
    "validation_qrels = pd.DataFrame(validation_dataset.qrels_iter()).rename(columns={\"query_id\": \"qid\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec720daa-57af-4070-b3a1-cfcd87c83485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               qid            docno     score  \\\n",
      "0       q062210081  doc062200602177  7.722567   \n",
      "1       q062210081  doc062200206592  7.718526   \n",
      "2       q062210081  doc062200201629  7.714514   \n",
      "3       q062210081  doc062210912628  7.703608   \n",
      "4       q062210081  doc062201201840  7.691112   \n",
      "...            ...              ...       ...   \n",
      "457611   q06229908  doc062201007812  2.758472   \n",
      "457612   q06229908  doc062204608629  2.758409   \n",
      "457613   q06229908  doc062203900979  2.758266   \n",
      "457614   q06229908  doc062200114940  2.758258   \n",
      "457615   q06229908  doc062200113336  2.758244   \n",
      "\n",
      "                                   features  \n",
      "0              [1.0, 8.41192338523742, 5.0]  \n",
      "1             [2.0, 8.864250453721736, 4.0]  \n",
      "2             [3.0, 9.519325132152874, 3.0]  \n",
      "3              [4.0, 8.09223216041958, 8.0]  \n",
      "4            [5.0, 7.212775139416361, 29.0]  \n",
      "...                                     ...  \n",
      "457611   [993.0, 2.0082993251888093, 942.0]  \n",
      "457612    [995.0, 2.007101073424835, 945.0]  \n",
      "457613   [998.0, 1.9192959147059976, 992.0]  \n",
      "457614   [999.0, 1.9669124606256665, 970.0]  \n",
      "457615  [1000.0, 2.0584979842011624, 903.0]  \n",
      "\n",
      "[457616 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_results = pd.merge(bm25_results, lm_results, on=['qid', 'docno'])\n",
    "merged_results['features'] = merged_results.apply(lambda row: np.array([row['rank_x'], row['score_y'], row['rank_y']]), axis=1)\n",
    "merged_results = merged_results.rename(columns={'doc_id': 'docno', 'score_x': 'score'})\n",
    "new_df = merged_results[['qid', 'docno', 'score', 'features']]\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb92562-4713-4c96-bbce-61ba2f70a131",
   "metadata": {},
   "source": [
    "## LTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6aa1349-4380-4d05-9a07-a793b9736d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(Transformer(), FUnion(Transformer(), pt.apply.doc_score()))\n"
     ]
    }
   ],
   "source": [
    "bm25 = pt.Transformer.from_df(bm25_results)\n",
    "lm = pt.Transformer.from_df(lm_results)\n",
    "featureA = pt.apply.doc_score(lambda row: row['rank'])\n",
    "\n",
    "pipeline = bm25 >> (lm ** featureA)\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53828ceb-c8fd-4afc-bb49-e8fd0616276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pipeline = pt.Transformer.from_df(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f7a9b75-c893-4fe4-9869-0457c14f6342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pt.Experiment([bm25, lm, pipeline], pd.DataFrame(training_queries), training_qrels, eval_metrics=['ndcg_cut_5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8703a204-471d-4a70-8c9b-bbc65331d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0023848-50e3-4731-a5b9-9515adce3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_qrels = training_qrels.rename(columns={'doc_id': 'docno', 'relevance': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc3b79d7-cd0d-4d26-9aef-af793414ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe = new_pipeline >> pt.ltr.apply_learned_model(rf)\n",
    "rf_pipe.fit(pd.DataFrame(training_queries), training_qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63cb96c4-7ca2-4721-8e54-808e692d9512",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unkonwn measure NDCG@5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExperiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbm25\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrf_pipe\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_queries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_qrels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNDCG@5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNDCG@10\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mP@10\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBM25 Baseline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLM Baseline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLTR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/pipelines.py:450\u001b[0m, in \u001b[0;36mExperiment\u001b[0;34m(retr_systems, topics, qrels, eval_metrics, names, perquery, dataframe, batch_size, filter_by_qrels, filter_by_topics, baseline, test, correction, correction_alpha, highlight, round, verbose, save_dir, save_mode, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     save_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.res.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n\u001b[0;32m--> 450\u001b[0m time, evalMeasuresDict \u001b[38;5;241m=\u001b[39m \u001b[43m_run_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqrels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mperquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperquery\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackfill_qids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_topic_qids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mperquery\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m baseline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     evalDictsPerQ\u001b[38;5;241m.\u001b[39mappend(evalMeasuresDict)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/pipelines.py:138\u001b[0m, in \u001b[0;36m_run_and_evaluate\u001b[0;34m(system, topics, qrels, metrics, pbar, save_mode, save_file, perquery, batch_size, backfill_qids)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m    136\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m tqdm(disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 138\u001b[0m metrics, rev_mapping \u001b[38;5;241m=\u001b[39m \u001b[43m_convert_measures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m qrels \u001b[38;5;241m=\u001b[39m qrels\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocno\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelevance\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtimeit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m default_timer \u001b[38;5;28;01mas\u001b[39;00m timer\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/pipelines.py:64\u001b[0m, in \u001b[0;36m_convert_measures\u001b[0;34m(metrics)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 64\u001b[0m     measures \u001b[38;5;241m=\u001b[39m \u001b[43mparse_trec_measure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(measures) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     66\u001b[0m         metric \u001b[38;5;241m=\u001b[39m measures[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ir_measures/util.py:432\u001b[0m, in \u001b[0;36mparse_trec_measure\u001b[0;34m(measure)\u001b[0m\n\u001b[1;32m    430\u001b[0m match \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, matches), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munkonwn measure \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(measure))\n\u001b[1;32m    433\u001b[0m base_meas, meas_args \u001b[38;5;241m=\u001b[39m match[\u001b[38;5;241m0\u001b[39m], match[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    434\u001b[0m meas, arg_name, _ \u001b[38;5;241m=\u001b[39m TREC_NAME_MAP[base_meas]\n",
      "\u001b[0;31mValueError\u001b[0m: unkonwn measure NDCG@5"
     ]
    }
   ],
   "source": [
    "pt.Experiment([bm25, lm, rf_pipe], pd.DataFrame(training_queries), training_qrels, eval_metrics=['NDCG@5', 'NDCG@10', 'P@10'], names=[\"BM25 Baseline\", \"LM Baseline\", \"LTR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf302484-de95-48aa-b00f-9b00cb3c16d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pt.Experiment([bm25, lm, bm25 >> lm], pd.DataFrame(training_queries), training_qrels, eval_metrics=['ndcg_cut_5'], names=[\"BM25 Baseline\", \"LM Baseline\", \"Combines\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70312a56-c778-4a8b-809f-fdf025dd1aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
